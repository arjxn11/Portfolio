[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home Page",
    "section": "",
    "text": "Welcome to Arjun’s website, we are glad to have you here!\nHere you can find descriptions and files relating to projects he has completed in the past, and some stuff that he is working on.\nBeyond this, you will be able to find his details should you be interested in contacting him!\n“It always seems impossible until its done.”"
  },
  {
    "objectID": "exp.html",
    "href": "exp.html",
    "title": "Education and Experience",
    "section": "",
    "text": "Arjun has completed a Masters degree, majoring in Data Science and Analytics, at Singapore Management University. The MITB Program is ranked 24th in the world for Analytics masters.\nDuring this masters degree, he gained valuable hands-on experience with essential data science techniques and in multiple analytical domains including Geospatial Analytics, Text Analytics and NLP, Customer and Market Analytics.\nBeyond this, he was able to complete projects using a variety of tools such as Python, R, Excel, Power BI, SAS Viya, and Solidity. The flexibility provided by the course also enabled Arjun to gain valuable experience in the world of Financial and Blockchain Technologies (FinTech), learning back-testing methods, key market indicators and risk management methods when working in Financial Service Institutions in addition to developing smart contracts and decentralised applications for commercial use.\nCourses studied: Data Science for Business, Customer Analytics, Blockchain Technology, Financial Market Systems and Technology, Text Analytics, Data Science for Financial Services, Geospatial Analytics, Spreadsheet Modelling, Applied Statistical Analysis with R, Data Analytics Lab, IT Project and Vendor Management.\n\n\nPrior to his masters degree, Arjun completed his Bachelors Degree in Data Science. During the course of his Bachelors degree, he gained hands-on experience in Machine Learning which he applied in projects going forward. Beyond this, he gained exposure to more analytical tools such as SPSS.\nFinally, Arjun has also completed a Graduate Diploma in Management, learning key modules such such as Econometrics and Game Theory, which adds to his toolkit as an analyst."
  },
  {
    "objectID": "exp.html#education",
    "href": "exp.html#education",
    "title": "Education and Experience",
    "section": "",
    "text": "Arjun has completed a Masters degree, majoring in Data Science and Analytics, at Singapore Management University. The MITB Program is ranked 24th in the world for Analytics masters.\nDuring this masters degree, he gained valuable hands-on experience with essential data science techniques and in multiple analytical domains including Geospatial Analytics, Text Analytics and NLP, Customer and Market Analytics.\nBeyond this, he was able to complete projects using a variety of tools such as Python, R, Excel, Power BI, SAS Viya, and Solidity. The flexibility provided by the course also enabled Arjun to gain valuable experience in the world of Financial and Blockchain Technologies (FinTech), learning back-testing methods, key market indicators and risk management methods when working in Financial Service Institutions in addition to developing smart contracts and decentralised applications for commercial use.\nCourses studied: Data Science for Business, Customer Analytics, Blockchain Technology, Financial Market Systems and Technology, Text Analytics, Data Science for Financial Services, Geospatial Analytics, Spreadsheet Modelling, Applied Statistical Analysis with R, Data Analytics Lab, IT Project and Vendor Management.\n\n\nPrior to his masters degree, Arjun completed his Bachelors Degree in Data Science. During the course of his Bachelors degree, he gained hands-on experience in Machine Learning which he applied in projects going forward. Beyond this, he gained exposure to more analytical tools such as SPSS.\nFinally, Arjun has also completed a Graduate Diploma in Management, learning key modules such such as Econometrics and Game Theory, which adds to his toolkit as an analyst."
  },
  {
    "objectID": "exp.html#experience",
    "href": "exp.html#experience",
    "title": "Education and Experience",
    "section": "Experience",
    "text": "Experience\n\nDanone\n\nArjun was the Regional SOP Demand and Performance intern completing a 7 month internship at Danone, a global leader in Dairy and Plant Based Products, parent company of brands such as Evian, Activia, Oikos, Nutricia, Volvic, Aptamil, and more.\nDuring this Internship he was primarily responsible for developing Business Intelligence tools in order to better visualize the vast amount of data being used by the supply chain team. To facilitate this process, he developed several metrics in order to automate the processes and make month-to-month and year-to-year transitions seamless.\nAs a part of the above task, he focused on streamlining data sources and making data easily traceable to boost explainability of the results being shown so that insights drawn can be accurate.\nArjun was responsible for end-to-end data ETL processes on a monthly basis, taking in CBU raw Sales Volumes, Stock data, and Sell-Out volumes, and consolidating it into a file that is used by the team and the BI tools. For this process, he developed a Python script with to facilitate automation and largely improved error handling processes, enabling even the layman to debug any errors that are experienced in the consolidation process. This reduced manual workload significantly and opened up resources to be deployed in another manner.\nAdditionally, he worked with a different teams in the organization, the Demand team, the Performance team, and even the HR team, to develop BI tools and/or metrics for each of them, and completing various tasks for all.\nHe also was given to opportunity to work on his Machine Learning skills by working on a Global Time Series Model for forecasting volumes. With this, he was able to improve his Machine Learning skill set by implementing different models such as ARIMA, SARIMA, Smoothing and more, and also developing his feature engineering abilities.\n\n\nSingapore Management University\nArjun was a Graduate Teaching Assistant for IS630: Statistical Thinking for Data Science. This course was primarily focused on implementing Python to perform Data Science processes, including data cleaning, feature engineering and insight generation.\nAs part of this role, he was responsible for facilitating student understanding of the coding and statistical concepts necessary to do this course to the best of ones ability. Additionally, he promptly responded to and addressed student inquiries and doubts as they came up, and acted as the bridge between the students and the professor, fostering an active and collaborative learning environment, while facilitating a communication line between the professor and the students.\n\n\nMiscellaneous\nArjun has also dabbled in Social Media Management, boosting engagement rates by over 200% and creating a network of established individuals in the relevant industries through collaboration and communication. He also worked as a freelance writer and wrote articles focusing on Health and Lifestyle, and occasionally sports."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "escentials.html",
    "href": "escentials.html",
    "title": "Essentials for Escentials",
    "section": "",
    "text": "This project involved working with the team at LUXASIA, responsible for their brand Escentials, to generate an approach to improve customer retention as well as customer conversion to their online e-commerce platform.\n\n\n\n\n\n\nAt the start of every data science project comes the data preprocessing step. Cleaning up the data off the noise is important and solves 50% of the problem.\nWith transactional data and the vast amount of rows, there is a lot of false data rows, fake names, fake emails, different formats for names and more, so the first thing we did was to ensure that the data was standard across and removed null rows, rows with $00.00 purchase value etc.\n\n\n\n\n\nAfter data cleaning, the first thing done was some exploratory analysis to gain a better idea of the customer base of the company and how well they perform with regards to customer retention.\n\n\n\nThe customers were segmented using RFM (Recency, Frequency, Monetary) segmentation techniques. This technique splits users and gives them different scores on a scale from 1-5 based on how recently they made their last purchase, how often they purchase, and how much money they have spent with the company in the past. This is then combined to generate different bands, such as 555 for the most loyal customers, and 111 for the customers with the least scores in each department.\nUsing this, Arjun was able to generate insights for the team at Escentials, identifying the most common products being purchased by the most loyal customers, understanding the frequency of it, and presenting it to the team at Escentials. Information like this allows them to create better informed marketing strategies to improve the RFM scores of other customers that aren’t so loyal.\n\n\n\nFor the recommendation system, Collaborative Filtering techniques were adopted. This technique is generally used to predict user preferences based on the preferences of similar users, based on their segments, such as by RFM, geolocation, etc.\nWe split the provided data into an 80/20 training/test split and trained our model. We tested to see if the accuracy of the recommendations on the ‘unseen’ data and discovered a 20% improvement in precision compared to more traditional models."
  },
  {
    "objectID": "escentials.html#overview",
    "href": "escentials.html#overview",
    "title": "Essentials for Escentials",
    "section": "",
    "text": "This project involved working with the team at LUXASIA, responsible for their brand Escentials, to generate an approach to improve customer retention as well as customer conversion to their online e-commerce platform."
  },
  {
    "objectID": "hedgefund.html",
    "href": "hedgefund.html",
    "title": "Hedge Fund Simulation",
    "section": "",
    "text": "As part of his studies, Arjun was given the opportunity to work in a simulated environment and gain hands-on experience on what its like to work at a Hedge Fund and make trading decisions.\nThe platform used was Saxo and real market prices were being used (with a 10 minute delay) so that our decisions were made keeping real market conditions and the real world in mind.\nDuring this 5 week simulation, several real world events took place, from feuds between the President of the US and the CEO of Apple, to conflicts being escalated in different regions of the world. Systems were thoroughly tested to see how they perform in such volatile conditions.\n\n\nThe simulation had the following results:\n\nTotal Growth: +9.28%\nWeeks ended with a positive return: 4/5\nTotal trades: 201\nTrade ‘win’ percentage: 67%\n\n\nThe market benchmark we used was the S&P 500 index. During the 5 week period of simulation, it had a growth of +3.8%. The Hedge Fund, backed by Arjuns strategy outperformed it by well over 200%.\n\n\n\n\nArjun developed and implemented an intraday trading strategy designed to eliminate overnight risk by closing all positions before market close.\nThis approach was particularly relevant during periods of heightened geopolitical uncertainty, such as Middle East tensions and tariff-related developments, which frequently triggered significant after-hours volatility.\nThis was combined with back-testing data going an year back (sometimes more depending on asset class) to gain a deeper understanding into daily/seasonal market trends and spot high value entry signals. Additionally, Monte-Carlo techniques were used to simulate returns, and the fund was simulated to grow at rate over the market benchmark a majority of the simulations.\nStrong risk management protocols were followed throughout. Pre-determined exit points were determined and followed in order to prevent significant downside exposure as capital preservation was a key focus for the fund. The fund avoided the sunk cost fallacy, and were not afraid to exit positions early if the trend was unfavorable to the position being held by the hedge fund.\n\n\n\nWeekly investor grade newsletters were written to provide the Hedge Funds results and rationale for the week. In this newsletter, the outlook the short and long term based on real world events were also provided.\nTo read the pitchbook, click HERE.\nIf you are interested in the newsletters, do not hesitate to reach out!"
  },
  {
    "objectID": "hedgefund.html#hedge-fund-simulation",
    "href": "hedgefund.html#hedge-fund-simulation",
    "title": "Hedge Fund Simulation",
    "section": "",
    "text": "As part of his studies, Arjun was given the opportunity to work in a simulated environment and gain hands-on experience on what its like to work at a Hedge Fund and make trading decisions.\nThe platform used was Saxo and real market prices were being used (with a 10 minute delay) so that our decisions were made keeping real market conditions and the real world in mind.\nDuring this 5 week simulation, several real world events took place, from feuds between the President of the US and the CEO of Apple, to conflicts being escalated in different regions of the world. Systems were thoroughly tested to see how they perform in such volatile conditions.\n\n\nThe simulation had the following results:\n\nTotal Growth: +9.28%\nWeeks ended with a positive return: 4/5\nTotal trades: 201\nTrade ‘win’ percentage: 67%\n\n\nThe market benchmark we used was the S&P 500 index. During the 5 week period of simulation, it had a growth of +3.8%. The Hedge Fund, backed by Arjuns strategy outperformed it by well over 200%.\n\n\n\n\nArjun developed and implemented an intraday trading strategy designed to eliminate overnight risk by closing all positions before market close.\nThis approach was particularly relevant during periods of heightened geopolitical uncertainty, such as Middle East tensions and tariff-related developments, which frequently triggered significant after-hours volatility.\nThis was combined with back-testing data going an year back (sometimes more depending on asset class) to gain a deeper understanding into daily/seasonal market trends and spot high value entry signals. Additionally, Monte-Carlo techniques were used to simulate returns, and the fund was simulated to grow at rate over the market benchmark a majority of the simulations.\nStrong risk management protocols were followed throughout. Pre-determined exit points were determined and followed in order to prevent significant downside exposure as capital preservation was a key focus for the fund. The fund avoided the sunk cost fallacy, and were not afraid to exit positions early if the trend was unfavorable to the position being held by the hedge fund.\n\n\n\nWeekly investor grade newsletters were written to provide the Hedge Funds results and rationale for the week. In this newsletter, the outlook the short and long term based on real world events were also provided.\nTo read the pitchbook, click HERE.\nIf you are interested in the newsletters, do not hesitate to reach out!"
  },
  {
    "objectID": "escentials.html#the-project",
    "href": "escentials.html#the-project",
    "title": "Essentials for Escentials",
    "section": "",
    "text": "This project involved working with the team at LUXASIA, responsible for their brand Escentials, to generate an approach to improve customer retention as well as customer conversion to their online e-commerce platform.\n\n\n\n\n\n\nAt the start of every data science project comes the data preprocessing step. Cleaning up the data off the noise is important and solves 50% of the problem.\nWith transactional data and the vast amount of rows, there is a lot of false data rows, fake names, fake emails, different formats for names and more, so the first thing we did was to ensure that the data was standard across and removed null rows, rows with $00.00 purchase value etc.\n\n\n\n\n\nAfter data cleaning, the first thing done was some exploratory analysis to gain a better idea of the customer base of the company and how well they perform with regards to customer retention.\n\n\n\nThe customers were segmented using RFM (Recency, Frequency, Monetary) segmentation techniques. This technique splits users and gives them different scores on a scale from 1-5 based on how recently they made their last purchase, how often they purchase, and how much money they have spent with the company in the past. This is then combined to generate different bands, such as 555 for the most loyal customers, and 111 for the customers with the least scores in each department.\nUsing this, Arjun was able to generate insights for the team at Escentials, identifying the most common products being purchased by the most loyal customers, understanding the frequency of it, and presenting it to the team at Escentials. Information like this allows them to create better informed marketing strategies to improve the RFM scores of other customers that aren’t so loyal.\n\n\n\nFor the recommendation system, Collaborative Filtering techniques were adopted. This technique is generally used to predict user preferences based on the preferences of similar users, based on their segments, such as by RFM, geolocation, etc.\nWe split the provided data into an 80/20 training/test split and trained our model. We tested to see if the accuracy of the recommendations on the ‘unseen’ data and discovered a 20% improvement in precision compared to more traditional models."
  }
]